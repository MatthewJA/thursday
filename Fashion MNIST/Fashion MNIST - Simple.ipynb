{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "from scipy.misc import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\n",
    "import keras.datasets as d\n",
    "\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "\n",
    "from IPython.core.pylabtools import figsize, getfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting directory paths \n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "\n",
    "# check for existence\n",
    "os.path.exists(root_dir)\n",
    "os.path.exists(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading and Preprocessing\n",
    "(train_x, train_y), (test_x, test_y) = d.fashion_mnist.load_data()\n",
    "\n",
    "train_x = np.asarray(train_x).astype('float32') \n",
    "train_y = np.asarray(train_y).astype('float32') \n",
    "test_x = np.asarray(test_x).astype('float32') \n",
    "test_y = np.asarray(test_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimg_train = np.reshape(train_x, (60000, 28, 28))\\npyplot.imshow(img_train[356,:,:], cmap='gray', shape=(28, 28))\\npyplot.show()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display image\n",
    "\"\"\"\n",
    "img_train = np.reshape(train_x, (60000, 28, 28))\n",
    "pyplot.imshow(img_train[356,:,:], cmap='gray', shape=(28, 28))\n",
    "pyplot.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications\n",
    "train_x /= 255.0\n",
    "test_x /= 255.0\n",
    "\n",
    "from keras.utils import np_utils\n",
    "nb_classes = 10\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "train_y = np_utils.to_categorical(train_y, 10)\n",
    "test_y = np_utils.to_categorical(test_y, 10)\n",
    "\n",
    "# Flatten Training and Testing Data\n",
    "train_x = np.reshape(train_x, (-1, 784))\n",
    "test_x = np.reshape(test_x, (-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "input_num_units = 784\n",
    "hidden1_num_units = 50\n",
    "hidden2_num_units = 50\n",
    "hidden3_num_units = 50\n",
    "hidden4_num_units = 50\n",
    "hidden5_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "# import keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "# model = model_from_json(open('my_model_architecture.json').read())# if json \n",
    "# model.load_weights('my_model_weights.h5')\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=output_num_units, input_dim = input_num_units, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fires\\Anaconda3\\envs\\CSIRO\\lib\\site-packages\\keras\\models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.7353 - acc: 0.7590 - val_loss: 0.5735 - val_acc: 0.8047\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.5131 - acc: 0.8295 - val_loss: 0.5171 - val_acc: 0.8248\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4725 - acc: 0.8418 - val_loss: 0.4886 - val_acc: 0.8332\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.4510 - acc: 0.8469 - val_loss: 0.4788 - val_acc: 0.8343\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.4364 - acc: 0.8512 - val_loss: 0.4680 - val_acc: 0.8360\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.4278 - acc: 0.8543 - val_loss: 0.4628 - val_acc: 0.8388\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.4204 - acc: 0.8563 - val_loss: 0.4579 - val_acc: 0.8398\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4139 - acc: 0.8579 - val_loss: 0.4508 - val_acc: 0.8414\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4095 - acc: 0.8597 - val_loss: 0.4493 - val_acc: 0.8438\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4049 - acc: 0.8608 - val_loss: 0.4484 - val_acc: 0.8423\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.4018 - acc: 0.8612 - val_loss: 0.4466 - val_acc: 0.8432\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3986 - acc: 0.8627 - val_loss: 0.4455 - val_acc: 0.8436\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3957 - acc: 0.8645 - val_loss: 0.4452 - val_acc: 0.8428\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3934 - acc: 0.8644 - val_loss: 0.4460 - val_acc: 0.8426\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3924 - acc: 0.8647 - val_loss: 0.4435 - val_acc: 0.8444\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3897 - acc: 0.8646 - val_loss: 0.4433 - val_acc: 0.8450\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3871 - acc: 0.8668 - val_loss: 0.4421 - val_acc: 0.8464\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3858 - acc: 0.8666 - val_loss: 0.4437 - val_acc: 0.8449\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3852 - acc: 0.8666 - val_loss: 0.4367 - val_acc: 0.8475\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3842 - acc: 0.8660 - val_loss: 0.4655 - val_acc: 0.8351\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3818 - acc: 0.8679 - val_loss: 0.4362 - val_acc: 0.8461\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3804 - acc: 0.8682 - val_loss: 0.4445 - val_acc: 0.8455\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3794 - acc: 0.8680 - val_loss: 0.4433 - val_acc: 0.8433\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3780 - acc: 0.8689 - val_loss: 0.4365 - val_acc: 0.8480\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3762 - acc: 0.8687 - val_loss: 0.4365 - val_acc: 0.8470\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3771 - acc: 0.8684 - val_loss: 0.4378 - val_acc: 0.8466\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3756 - acc: 0.8689 - val_loss: 0.4392 - val_acc: 0.8448\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3752 - acc: 0.8691 - val_loss: 0.4462 - val_acc: 0.8445\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.3748 - acc: 0.8694 - val_loss: 0.4444 - val_acc: 0.8458\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3726 - acc: 0.8699 - val_loss: 0.4416 - val_acc: 0.8455\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3717 - acc: 0.8705 - val_loss: 0.4429 - val_acc: 0.8459\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3711 - acc: 0.8700 - val_loss: 0.4399 - val_acc: 0.8458\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3707 - acc: 0.8697 - val_loss: 0.4365 - val_acc: 0.8465\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3699 - acc: 0.8705 - val_loss: 0.4377 - val_acc: 0.8458\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3700 - acc: 0.8705 - val_loss: 0.4370 - val_acc: 0.8466\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3683 - acc: 0.8717 - val_loss: 0.4365 - val_acc: 0.8471\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3689 - acc: 0.8701 - val_loss: 0.4480 - val_acc: 0.8432\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3698 - acc: 0.8706 - val_loss: 0.4362 - val_acc: 0.8470\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3673 - acc: 0.8711 - val_loss: 0.4419 - val_acc: 0.8446\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3656 - acc: 0.8721 - val_loss: 0.4395 - val_acc: 0.8474\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3665 - acc: 0.8711 - val_loss: 0.4447 - val_acc: 0.8436\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3656 - acc: 0.8713 - val_loss: 0.4386 - val_acc: 0.8477\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3655 - acc: 0.8721 - val_loss: 0.4361 - val_acc: 0.8456\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3658 - acc: 0.8714 - val_loss: 0.4394 - val_acc: 0.8480\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3649 - acc: 0.8718 - val_loss: 0.4437 - val_acc: 0.8447\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3645 - acc: 0.8720 - val_loss: 0.4491 - val_acc: 0.8424\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3642 - acc: 0.8715 - val_loss: 0.4386 - val_acc: 0.8452\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3636 - acc: 0.8725 - val_loss: 0.4415 - val_acc: 0.8448\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3644 - acc: 0.8712 - val_loss: 0.4373 - val_acc: 0.8447\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3626 - acc: 0.8721 - val_loss: 0.4448 - val_acc: 0.8448\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3624 - acc: 0.8727 - val_loss: 0.4425 - val_acc: 0.8459\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3620 - acc: 0.8724 - val_loss: 0.4456 - val_acc: 0.8451\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3617 - acc: 0.8723 - val_loss: 0.4445 - val_acc: 0.8454\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3621 - acc: 0.8734 - val_loss: 0.4467 - val_acc: 0.8460\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3609 - acc: 0.8734 - val_loss: 0.4420 - val_acc: 0.8470\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3603 - acc: 0.8736 - val_loss: 0.4427 - val_acc: 0.8460\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3604 - acc: 0.8722 - val_loss: 0.4395 - val_acc: 0.8461\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3600 - acc: 0.8741 - val_loss: 0.4466 - val_acc: 0.8464\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3591 - acc: 0.8745 - val_loss: 0.4430 - val_acc: 0.8448\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3595 - acc: 0.8732 - val_loss: 0.4487 - val_acc: 0.8439\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3591 - acc: 0.8733 - val_loss: 0.4415 - val_acc: 0.8459\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3579 - acc: 0.8735 - val_loss: 0.4435 - val_acc: 0.8448\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3585 - acc: 0.8744 - val_loss: 0.4462 - val_acc: 0.8453\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3591 - acc: 0.8741 - val_loss: 0.4435 - val_acc: 0.8460\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3584 - acc: 0.8739 - val_loss: 0.4435 - val_acc: 0.8460\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.3566 - acc: 0.8751 - val_loss: 0.4461 - val_acc: 0.8440\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3574 - acc: 0.8743 - val_loss: 0.4461 - val_acc: 0.8431\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3570 - acc: 0.8737 - val_loss: 0.4446 - val_acc: 0.8442\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3576 - acc: 0.8748 - val_loss: 0.4451 - val_acc: 0.8450\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3569 - acc: 0.8737 - val_loss: 0.4523 - val_acc: 0.8445\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3564 - acc: 0.8746 - val_loss: 0.4497 - val_acc: 0.8434\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3560 - acc: 0.8741 - val_loss: 0.4433 - val_acc: 0.8438\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3556 - acc: 0.8748 - val_loss: 0.4515 - val_acc: 0.8420\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.3558 - acc: 0.8751 - val_loss: 0.4495 - val_acc: 0.8433\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3548 - acc: 0.8746 - val_loss: 0.4560 - val_acc: 0.8416\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3563 - acc: 0.8739 - val_loss: 0.4463 - val_acc: 0.8457\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3548 - acc: 0.8750 - val_loss: 0.4482 - val_acc: 0.8424\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3541 - acc: 0.8745 - val_loss: 0.4469 - val_acc: 0.8448\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3544 - acc: 0.8749 - val_loss: 0.4446 - val_acc: 0.8464\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3549 - acc: 0.8747 - val_loss: 0.4451 - val_acc: 0.8452\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3534 - acc: 0.8754 - val_loss: 0.4449 - val_acc: 0.8457\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3548 - acc: 0.8748 - val_loss: 0.4429 - val_acc: 0.8458\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3542 - acc: 0.8755 - val_loss: 0.4449 - val_acc: 0.8452\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3536 - acc: 0.8754 - val_loss: 0.4446 - val_acc: 0.8458\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3539 - acc: 0.8750 - val_loss: 0.4436 - val_acc: 0.8461\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.3523 - acc: 0.8752 - val_loss: 0.4494 - val_acc: 0.8444\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.3539 - acc: 0.8745 - val_loss: 0.4522 - val_acc: 0.8438\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3532 - acc: 0.8756 - val_loss: 0.4499 - val_acc: 0.8458\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3529 - acc: 0.8758 - val_loss: 0.4544 - val_acc: 0.8431\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3518 - acc: 0.8756 - val_loss: 0.4456 - val_acc: 0.8438\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3520 - acc: 0.8754 - val_loss: 0.4499 - val_acc: 0.8424\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3527 - acc: 0.8754 - val_loss: 0.4475 - val_acc: 0.8434\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 0.3519 - acc: 0.8758 - val_loss: 0.4497 - val_acc: 0.8454\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3516 - acc: 0.8757 - val_loss: 0.4494 - val_acc: 0.8448\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3516 - acc: 0.8758 - val_loss: 0.4531 - val_acc: 0.8417\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 0.3507 - acc: 0.8763 - val_loss: 0.4581 - val_acc: 0.8400\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3513 - acc: 0.8757 - val_loss: 0.4617 - val_acc: 0.8397\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.3518 - acc: 0.8751 - val_loss: 0.4537 - val_acc: 0.8414\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3510 - acc: 0.8763 - val_loss: 0.4463 - val_acc: 0.8452\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3507 - acc: 0.8770 - val_loss: 0.4477 - val_acc: 0.8442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ad0c40e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size,\n",
    "         validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()  #as json\n",
    "open('mnist_Logistic_model.json', 'w').write(json_string)\n",
    "\n",
    "# save the weights in h5 format\n",
    "model.save_weights('mnist_Logistic_wts.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
