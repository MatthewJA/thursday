{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import *\n",
    "import os\n",
    "import h5py\n",
    "import keras as k\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, adam\n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting directory paths \n",
    "root_dir = os.getcwd()\n",
    "\n",
    "# Loading data\n",
    "data = h5py.File(r'C:\\\\Users\\\\fires\\\\Desktop\\\\CSIRO\\\\thursday\\\\Logistic Regression\\\\data.h5', 'r')\n",
    "\n",
    "images = np.asarray(data['images'])\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to crop off 'cut' number of pixels on both sides on both axixs\n",
    "def crop_center(img,cut):\n",
    "    y = np.shape(img)[1]\n",
    "    x = np.shape(img)[2]\n",
    "    if x != y:\n",
    "        print (\"The image is not a perfect sqaure. This is bad. Fix it \")\n",
    "        \n",
    "    start = cut\n",
    "    end = x-cut\n",
    "    return img[:, start:end,start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining rescaling function\n",
    "def rescale_imgs(images, factor):\n",
    "    count =  0\n",
    "    for i in range(0 ,images.shape[0]):\n",
    "        img_scaled = expand_dims(rescale(images[i, :, :], 1.0 / float(factor)), axis = 0)\n",
    "        if count == 0:\n",
    "            imgs = img_scaled\n",
    "        else:\n",
    "            imgs = np.vstack((imgs, img_scaled))\n",
    "        count += 1\n",
    "                             \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing Image Size\n",
    "images_cut = crop_center(images,66)\n",
    "images_cut = np.asarray(images_cut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fires\\Anaconda3\\envs\\CSIRO\\lib\\site-packages\\skimage\\feature\\_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    }
   ],
   "source": [
    "hog_images  = []\n",
    "\n",
    "for i, image in enumerate(images_cut):\n",
    "    fd = hog(images_cut[i, :, :], orientations=8, pixels_per_cell=(8, 8),\n",
    "                        cells_per_block=(1, 1), feature_vector=True)\n",
    "    hog_images.append(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes\n",
    "def bal_classes(images, labels):\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    \n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == False:\n",
    "            class1.append(i)\n",
    "    \n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == True:\n",
    "            class2.append(i)\n",
    "    \n",
    "    if len(class2) > len(class1):\n",
    "        class2 = np.asarray(class2[:len(class1)])\n",
    "    \n",
    "    elif len(class2) < len(class1):\n",
    "        class1 = np.asarray(class1[:len(class2)])\n",
    "        \n",
    "    images1 = images[class1, :] \n",
    "    images2 = images[class2, :]\n",
    "    labels1 = labels[class1,]\n",
    "    labels2 = labels[class2,]\n",
    "    \n",
    "    print (labels2.shape)\n",
    "    \n",
    "    images_st = np.vstack((images1, images2))\n",
    "    labels_st =  np.concatenate((labels1, labels2), axis=0)              \n",
    "        \n",
    "    images_s, labels_s = shuffle(np.asarray(images_st), np.asarray(labels_st), random_state = 0)    \n",
    "        \n",
    "    return images_s, labels_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hog_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-aa7033d60276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimages_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbal_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhog_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hog_img' is not defined"
     ]
    }
   ],
   "source": [
    "images_p, labels_p = bal_classes(np.asarray(hog_images), np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs = np.reshape(images_p, (-1, 135, 135))\n",
    "\n",
    "#for n in range(0, imgs.shape[0]):\n",
    "   #plt.imshow(imgs[n,:,:], cmap='gray', shape=(135, 135))\n",
    "   #print (n)\n",
    "   #print (normalized_labels[n])\n",
    "   #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "\n",
    "def format_data(images, labels, ratio = 0.8):\n",
    "    split = round(ratio*images.shape[0])\n",
    "    \n",
    "    train_x = images[ :split, :]\n",
    "    test_x = images[split:, :]\n",
    "    train_y = labels[ :split]\n",
    "    test_y = labels[split:]\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = format_data(images_p, labels_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "train_y = np_utils.to_categorical(train_y, 2)\n",
    "test_y = np_utils.to_categorical(test_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model attributes\n",
    "batch_size = 20\n",
    "nb_classes = output_dims = 2\n",
    "nb_epoch = 50\n",
    "input_dim = 21632\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dims, input_dim = input_dim, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = adam(lr=0.1)\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, epochs=nb_epoch, batch_size=batch_size, \n",
    "          validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_hog.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_hog.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "\n",
    "wt = np.reshape(weights[0], (135, 135, 2))\n",
    "    \n",
    "for n in range(0, wt.shape[2]):\n",
    "   plt.imshow(wt[:,:,n], cmap='gray', shape=(135, 135))\n",
    "   print (n)\n",
    "   plt.show()\n",
    "\n",
    "print (\"Dense to output layer weights \" + str(weights[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
