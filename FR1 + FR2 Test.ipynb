{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "from scipy.misc import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation, Dropout, Convolution2D, Flatten, MaxPooling2D, Reshape, InputLayer\n",
    "import keras.datasets as d\n",
    "import h5py\n",
    "\n",
    "from pylab import *\n",
    "from numpy import *\n",
    "\n",
    "from IPython.core.pylabtools import figsize, getfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting directory paths \n",
    "root_dir = os.getcwd()\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "\n",
    "# check for existence\n",
    "os.path.exists(root_dir)\n",
    "os.path.exists(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File('data.h5', 'r')\n",
    "\n",
    "fr1 = data['fri_data']\n",
    "fr2 = data['frii_data']\n",
    "images = data['images']\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.reshape(images, (356, 71289))\n",
    "rows = round(images.shape[0])\n",
    "\n",
    "             \n",
    "# Spiltting data into training and testing sets             \n",
    "train_x = images[:round(rows*0.8), :]\n",
    "train_y = labels[:round(rows*0.8)]\n",
    "test_x = images[round(rows*0.8):, :]\n",
    "test_y = labels[round(rows*0.8):]\n",
    "\n",
    "train_x = np.asarray(train_x).astype('float32') \n",
    "train_y = np.asarray(train_y).astype('float32') \n",
    "test_x = np.asarray(test_x).astype('float32') \n",
    "test_y = np.asarray(test_y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimg_train = np.reshape(train_x, (60000, 28, 28))\\npyplot.imshow(img_train[356,:,:], cmap='gray', shape=(28, 28))\\npyplot.show()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display image\n",
    "\"\"\"\n",
    "img_train = np.reshape(train_x, (60000, 28, 28))\n",
    "pyplot.imshow(img_train[356,:,:], cmap='gray', shape=(28, 28))\n",
    "pyplot.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications\n",
    "\n",
    "from keras.utils import np_utils\n",
    "nb_classes = 2\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "train_y = np_utils.to_categorical(train_y, 2)\n",
    "test_y = np_utils.to_categorical(test_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "\n",
    "input_num_units = 71289\n",
    "hidden1_num_units = 500\n",
    "hidden2_num_units = 500\n",
    "hidden3_num_units = 500\n",
    "hidden4_num_units = 500\n",
    "hidden5_num_units = 500\n",
    "output_num_units = 2\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "dropout_ratio = 0.2\n",
    "\n",
    "# import keras modules\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "# model = model_from_json(open('fashion_mnist_Logistic_model.json').read())# if json \n",
    "# model.load_weights('fashion_mnist_Logistic_wts.h5')\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(units = hidden1_num_units, input_dim = input_num_units, activation = 'relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "\n",
    "model.add(Dense(units = hidden2_num_units, activation = 'relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "\n",
    "model.add(Dense(units = hidden3_num_units, activation = 'relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "                  \n",
    "model.add(Dense(units = hidden4_num_units, activation = 'relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "                \n",
    "model.add(Dense(units = hidden5_num_units, activation = 'relu'))\n",
    "model.add(Dropout(dropout_ratio))\n",
    "                  \n",
    "model.add(Dense(units=output_num_units, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fires\\Anaconda3\\envs\\CSIRO\\lib\\site-packages\\keras\\models.py:944: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 71 samples\n",
      "Epoch 1/100\n",
      "285/285 [==============================] - 22s 76ms/step - loss: 0.1725 - acc: 0.8000 - val_loss: 0.8327 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 0.0941 - acc: 0.8737 - val_loss: 0.2617 - val_acc: 0.7042\n",
      "Epoch 3/100\n",
      "285/285 [==============================] - 18s 64ms/step - loss: 0.0312 - acc: 0.9649 - val_loss: 0.5471 - val_acc: 0.3944\n",
      "Epoch 4/100\n",
      "285/285 [==============================] - 19s 65ms/step - loss: 0.0072 - acc: 0.9930 - val_loss: 0.7349 - val_acc: 0.2113\n",
      "Epoch 5/100\n",
      "285/285 [==============================] - 19s 65ms/step - loss: 0.0085 - acc: 0.9895 - val_loss: 0.9150 - val_acc: 0.0845\n",
      "Epoch 6/100\n",
      "285/285 [==============================] - 18s 64ms/step - loss: 0.0202 - acc: 0.9789 - val_loss: 0.7013 - val_acc: 0.2394\n",
      "Epoch 7/100\n",
      "285/285 [==============================] - 18s 65ms/step - loss: 0.0071 - acc: 0.9930 - val_loss: 0.8818 - val_acc: 0.1127\n",
      "Epoch 8/100\n",
      "285/285 [==============================] - 19s 67ms/step - loss: 0.0050 - acc: 0.9930 - val_loss: 0.6381 - val_acc: 0.3239\n",
      "Epoch 9/100\n",
      "285/285 [==============================] - 19s 67ms/step - loss: 0.0035 - acc: 0.9965 - val_loss: 0.6082 - val_acc: 0.3380\n",
      "Epoch 10/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 0.0222 - acc: 0.9719 - val_loss: 0.8047 - val_acc: 0.1831\n",
      "Epoch 11/100\n",
      "285/285 [==============================] - 18s 62ms/step - loss: 0.0047 - acc: 0.9965 - val_loss: 0.7435 - val_acc: 0.2394\n",
      "Epoch 12/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 4.0943e-06 - acc: 1.0000 - val_loss: 0.7137 - val_acc: 0.2676\n",
      "Epoch 13/100\n",
      "285/285 [==============================] - 17s 60ms/step - loss: 2.6946e-09 - acc: 1.0000 - val_loss: 0.7136 - val_acc: 0.2676\n",
      "Epoch 14/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 1.0437e-09 - acc: 1.0000 - val_loss: 0.7137 - val_acc: 0.2676\n",
      "Epoch 15/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 1.4771e-09 - acc: 1.0000 - val_loss: 0.7130 - val_acc: 0.2676\n",
      "Epoch 16/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 2.2838e-10 - acc: 1.0000 - val_loss: 0.7130 - val_acc: 0.2676\n",
      "Epoch 17/100\n",
      "285/285 [==============================] - 18s 62ms/step - loss: 3.2762e-10 - acc: 1.0000 - val_loss: 0.7120 - val_acc: 0.2676\n",
      "Epoch 18/100\n",
      "285/285 [==============================] - 19s 66ms/step - loss: 4.3815e-09 - acc: 1.0000 - val_loss: 0.6581 - val_acc: 0.3380\n",
      "Epoch 19/100\n",
      "285/285 [==============================] - 18s 61ms/step - loss: 1.5514e-09 - acc: 1.0000 - val_loss: 0.7500 - val_acc: 0.2254\n",
      "Epoch 20/100\n",
      "285/285 [==============================] - 18s 62ms/step - loss: 1.0041e-10 - acc: 1.0000 - val_loss: 0.7372 - val_acc: 0.2254\n",
      "Epoch 21/100\n",
      "285/285 [==============================] - 18s 64ms/step - loss: 3.8010e-11 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.2394\n",
      "Epoch 22/100\n",
      "285/285 [==============================] - 18s 62ms/step - loss: 1.5629e-10 - acc: 1.0000 - val_loss: 0.6893 - val_acc: 0.2817\n",
      "Epoch 23/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 0.0035 - acc: 0.9965 - val_loss: 0.9266 - val_acc: 0.0563\n",
      "Epoch 24/100\n",
      "285/285 [==============================] - 17s 59ms/step - loss: 0.0070 - acc: 0.9930 - val_loss: 0.8183 - val_acc: 0.1690\n",
      "Epoch 25/100\n",
      "285/285 [==============================] - 18s 62ms/step - loss: 0.0035 - acc: 0.9965 - val_loss: 0.6957 - val_acc: 0.2958\n",
      "Epoch 26/100\n",
      "285/285 [==============================] - 18s 63ms/step - loss: 0.0034 - acc: 0.9965 - val_loss: 0.0912 - val_acc: 0.9014\n",
      "Epoch 27/100\n",
      "285/285 [==============================] - 18s 62ms/step - loss: 0.0065 - acc: 0.9930 - val_loss: 0.7399 - val_acc: 0.2254\n",
      "Epoch 28/100\n",
      "285/285 [==============================] - 18s 64ms/step - loss: 1.1763e-10 - acc: 1.0000 - val_loss: 0.7401 - val_acc: 0.2254\n",
      "Epoch 29/100\n",
      "285/285 [==============================] - 18s 63ms/step - loss: 8.9814e-10 - acc: 1.0000 - val_loss: 0.7367 - val_acc: 0.2254\n",
      "Epoch 30/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 1.2883e-10 - acc: 1.0000 - val_loss: 0.7378 - val_acc: 0.2254\n",
      "Epoch 31/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 1.1688e-09 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.2254\n",
      "Epoch 32/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 2.1017e-10 - acc: 1.0000 - val_loss: 0.7208 - val_acc: 0.2254\n",
      "Epoch 33/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 4.7716e-10 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.2254\n",
      "Epoch 34/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 7.7547e-04 - acc: 1.0000 - val_loss: 0.7243 - val_acc: 0.2535\n",
      "Epoch 35/100\n",
      "285/285 [==============================] - 18s 63ms/step - loss: 2.4898e-14 - acc: 1.0000 - val_loss: 0.7243 - val_acc: 0.2535\n",
      "Epoch 36/100\n",
      "285/285 [==============================] - 18s 62ms/step - loss: 1.6295e-13 - acc: 1.0000 - val_loss: 0.7243 - val_acc: 0.2535\n",
      "Epoch 37/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 3.1715e-13 - acc: 1.0000 - val_loss: 0.7243 - val_acc: 0.2535\n",
      "Epoch 38/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 3.0745e-12 - acc: 1.0000 - val_loss: 0.7242 - val_acc: 0.2535\n",
      "Epoch 39/100\n",
      "285/285 [==============================] - 17s 61ms/step - loss: 1.0023e-12 - acc: 1.0000 - val_loss: 0.7242 - val_acc: 0.2535\n",
      "Epoch 40/100\n",
      "285/285 [==============================] - 18s 61ms/step - loss: 1.9928e-13 - acc: 1.0000 - val_loss: 0.7242 - val_acc: 0.2535\n",
      "Epoch 41/100\n",
      "285/285 [==============================] - 18s 62ms/step - loss: 2.6641e-11 - acc: 1.0000 - val_loss: 0.7262 - val_acc: 0.2535\n",
      "Epoch 42/100\n",
      "285/285 [==============================] - 19s 66ms/step - loss: 5.8014e-13 - acc: 1.0000 - val_loss: 0.7261 - val_acc: 0.2535\n",
      "Epoch 43/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 4.1286e-13 - acc: 1.0000 - val_loss: 0.7260 - val_acc: 0.2535\n",
      "Epoch 44/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 1.2651e-13 - acc: 1.0000 - val_loss: 0.7260 - val_acc: 0.2535\n",
      "Epoch 45/100\n",
      "285/285 [==============================] - 20s 71ms/step - loss: 3.0061e-12 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 0.2535\n",
      "Epoch 46/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 1.2642e-13 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 0.2535\n",
      "Epoch 47/100\n",
      "285/285 [==============================] - 19s 68ms/step - loss: 3.5102e-14 - acc: 1.0000 - val_loss: 0.7251 - val_acc: 0.2535\n",
      "Epoch 48/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 1.3799e-11 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.2535\n",
      "Epoch 49/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 1.7076e-13 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.2535\n",
      "Epoch 50/100\n",
      "285/285 [==============================] - 19s 68ms/step - loss: 4.2352e-14 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.2535\n",
      "Epoch 51/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 8.1954e-13 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.2535\n",
      "Epoch 52/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 6.3535e-12 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.2535\n",
      "Epoch 53/100\n",
      "285/285 [==============================] - 20s 68ms/step - loss: 1.6473e-13 - acc: 1.0000 - val_loss: 0.7294 - val_acc: 0.2535\n",
      "Epoch 54/100\n",
      "285/285 [==============================] - 20s 71ms/step - loss: 1.5347e-13 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.2535\n",
      "Epoch 55/100\n",
      "285/285 [==============================] - 20s 71ms/step - loss: 3.1154e-12 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 0.2535\n",
      "Epoch 56/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 6.1945e-13 - acc: 1.0000 - val_loss: 0.7329 - val_acc: 0.2535\n",
      "Epoch 57/100\n",
      "285/285 [==============================] - 19s 68ms/step - loss: 7.8169e-13 - acc: 1.0000 - val_loss: 0.7327 - val_acc: 0.2535\n",
      "Epoch 58/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 8.5572e-13 - acc: 1.0000 - val_loss: 0.7325 - val_acc: 0.2535\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 19s 68ms/step - loss: 1.7307e-13 - acc: 1.0000 - val_loss: 0.7325 - val_acc: 0.2535\n",
      "Epoch 60/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 4.4501e-13 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 0.2535\n",
      "Epoch 61/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 6.8397e-14 - acc: 1.0000 - val_loss: 0.7324 - val_acc: 0.2535\n",
      "Epoch 62/100\n",
      "285/285 [==============================] - 19s 67ms/step - loss: 3.7445e-13 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.2535\n",
      "Epoch 63/100\n",
      "285/285 [==============================] - 19s 68ms/step - loss: 6.1993e-14 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.2535\n",
      "Epoch 64/100\n",
      "285/285 [==============================] - 19s 67ms/step - loss: 6.4901e-14 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.2535\n",
      "Epoch 65/100\n",
      "285/285 [==============================] - 19s 67ms/step - loss: 3.0329e-12 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.2535\n",
      "Epoch 66/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 1.4914e-11 - acc: 1.0000 - val_loss: 0.7258 - val_acc: 0.2535\n",
      "Epoch 67/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 4.3251e-13 - acc: 1.0000 - val_loss: 0.7256 - val_acc: 0.2535\n",
      "Epoch 68/100\n",
      "285/285 [==============================] - 19s 68ms/step - loss: 2.5545e-14 - acc: 1.0000 - val_loss: 0.7256 - val_acc: 0.2535\n",
      "Epoch 69/100\n",
      "285/285 [==============================] - 19s 67ms/step - loss: 3.7494e-12 - acc: 1.0000 - val_loss: 0.7275 - val_acc: 0.2535\n",
      "Epoch 70/100\n",
      "285/285 [==============================] - 19s 68ms/step - loss: 8.2811e-13 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.2535\n",
      "Epoch 71/100\n",
      "285/285 [==============================] - 19s 68ms/step - loss: 4.6814e-12 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 0.2535\n",
      "Epoch 72/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 2.3154e-13 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 0.2535\n",
      "Epoch 73/100\n",
      "285/285 [==============================] - 20s 71ms/step - loss: 3.8779e-13 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.2535\n",
      "Epoch 74/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 6.7821e-14 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.2535\n",
      "Epoch 75/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 1.1476e-13 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.2535\n",
      "Epoch 76/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 3.1157e-13 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.2535\n",
      "Epoch 77/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 7.3851e-14 - acc: 1.0000 - val_loss: 0.7295 - val_acc: 0.2535\n",
      "Epoch 78/100\n",
      "285/285 [==============================] - 20s 71ms/step - loss: 8.7695e-13 - acc: 1.0000 - val_loss: 0.7291 - val_acc: 0.2535\n",
      "Epoch 79/100\n",
      "285/285 [==============================] - 20s 71ms/step - loss: 8.8377e-13 - acc: 1.0000 - val_loss: 0.7299 - val_acc: 0.2535\n",
      "Epoch 80/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 2.1830e-13 - acc: 1.0000 - val_loss: 0.7300 - val_acc: 0.2535\n",
      "Epoch 81/100\n",
      "285/285 [==============================] - 20s 69ms/step - loss: 9.4947e-12 - acc: 1.0000 - val_loss: 0.7258 - val_acc: 0.2535\n",
      "Epoch 82/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 3.7075e-13 - acc: 1.0000 - val_loss: 0.7257 - val_acc: 0.2535\n",
      "Epoch 83/100\n",
      "285/285 [==============================] - 20s 70ms/step - loss: 2.3393e-13 - acc: 1.0000 - val_loss: 0.7256 - val_acc: 0.2535\n",
      "Epoch 84/100\n",
      "285/285 [==============================] - 18s 65ms/step - loss: 4.0808e-13 - acc: 1.0000 - val_loss: 0.7258 - val_acc: 0.2535\n",
      "Epoch 85/100\n",
      "285/285 [==============================] - 20s 68ms/step - loss: 1.0265e-11 - acc: 1.0000 - val_loss: 0.7200 - val_acc: 0.2535\n",
      "Epoch 86/100\n",
      "285/285 [==============================] - 19s 67ms/step - loss: 1.1385e-12 - acc: 1.0000 - val_loss: 0.7196 - val_acc: 0.2535\n",
      "Epoch 87/100\n",
      "285/285 [==============================] - 19s 67ms/step - loss: 3.4030e-13 - acc: 1.0000 - val_loss: 0.7195 - val_acc: 0.2535\n",
      "Epoch 88/100\n",
      "285/285 [==============================] - 20s 72ms/step - loss: 1.0220e-13 - acc: 1.0000 - val_loss: 0.7194 - val_acc: 0.2535\n",
      "Epoch 89/100\n",
      "285/285 [==============================] - 19s 68ms/step - loss: 2.8950e-13 - acc: 1.0000 - val_loss: 0.7193 - val_acc: 0.2535\n",
      "Epoch 90/100\n",
      "285/285 [==============================] - 352s 1s/step - loss: 5.0649e-14 - acc: 1.0000 - val_loss: 0.7194 - val_acc: 0.2535\n",
      "Epoch 91/100\n",
      "285/285 [==============================] - 457s 2s/step - loss: 3.3090e-12 - acc: 1.0000 - val_loss: 0.7226 - val_acc: 0.2535\n",
      "Epoch 92/100\n",
      "285/285 [==============================] - 491s 2s/step - loss: 9.3177e-13 - acc: 1.0000 - val_loss: 0.7224 - val_acc: 0.2535\n",
      "Epoch 93/100\n",
      "285/285 [==============================] - 16s 57ms/step - loss: 1.0701e-12 - acc: 1.0000 - val_loss: 0.7226 - val_acc: 0.2535\n",
      "Epoch 94/100\n",
      "285/285 [==============================] - 502s 2s/step - loss: 4.2401e-14 - acc: 1.0000 - val_loss: 0.7225 - val_acc: 0.2535\n",
      "Epoch 95/100\n",
      "285/285 [==============================] - 15s 51ms/step - loss: 2.8053e-13 - acc: 1.0000 - val_loss: 0.7225 - val_acc: 0.2535\n",
      "Epoch 96/100\n",
      "285/285 [==============================] - 15s 52ms/step - loss: 7.8347e-13 - acc: 1.0000 - val_loss: 0.7234 - val_acc: 0.2535\n",
      "Epoch 97/100\n",
      "285/285 [==============================] - 14s 50ms/step - loss: 2.3679e-13 - acc: 1.0000 - val_loss: 0.7234 - val_acc: 0.2535\n",
      "Epoch 98/100\n",
      "285/285 [==============================] - 14s 50ms/step - loss: 4.8997e-11 - acc: 1.0000 - val_loss: 0.7023 - val_acc: 0.2676\n",
      "Epoch 99/100\n",
      "285/285 [==============================] - 98s 344ms/step - loss: 1.5747e-13 - acc: 1.0000 - val_loss: 0.7022 - val_acc: 0.2676\n",
      "Epoch 100/100\n",
      "285/285 [==============================] - 14s 48ms/step - loss: 2.0739e-13 - acc: 1.0000 - val_loss: 0.7021 - val_acc: 0.2676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2437ca02ac8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.adam(lr=0.001)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = 'rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size,\n",
    "         validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()  #as json\n",
    "open('fashion_mnist_Logistic_model.json', 'w').write(json_string)\n",
    "\n",
    "# save the weights in h5 format\n",
    "model.save_weights('fashion_mnist_Logistic_wts.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
