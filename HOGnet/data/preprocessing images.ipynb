{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import pickle as p\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import *\n",
    "import os\n",
    "import h5py\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, adam\n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "import pickle \n",
    "from skimage.transform import rescale, resize\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting directory paths \n",
    "root_dir = os.getcwd()\n",
    "\n",
    "# Loading data\n",
    "data = h5py.File(r'data.h5', 'r')\n",
    "\n",
    "images_raw = np.asarray(data['images'])\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356, 267, 267)\n"
     ]
    }
   ],
   "source": [
    "print(images_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes\n",
    "def bal_classes(images, labels):\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    \n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == False:\n",
    "            class1.append(i)\n",
    "    \n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == True:\n",
    "            class2.append(i)\n",
    "    \n",
    "    if len(class2) > len(class1):\n",
    "        class2 = np.asarray(class2[:len(class1)])\n",
    "    \n",
    "    elif len(class2) < len(class1):\n",
    "        class1 = np.asarray(class1[:len(class2)])\n",
    "        \n",
    "    images1 = images[class1, :] \n",
    "    images2 = images[class2, :]\n",
    "    labels1 = labels[class1,]\n",
    "    labels2 = labels[class2,]\n",
    "    \n",
    "    print (labels2.shape)\n",
    "    \n",
    "    images_st = np.vstack((images1, images2))\n",
    "    labels_st =  np.concatenate((labels1, labels2), axis=0)              \n",
    "        \n",
    "    images_s, labels_s = shuffle(np.asarray(images_st), np.asarray(labels_st), random_state = 0)    \n",
    "        \n",
    "    return images_s, labels_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123,)\n"
     ]
    }
   ],
   "source": [
    "images_p, labels_p = bal_classes(np.asarray(images_raw), np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining rescaling function\n",
    "def rescale_imgs(images):\n",
    "    count =  0\n",
    "    for i in range(0 ,images.shape[0]):\n",
    "        img_scaled = expand_dims(resize(images[i, :, :], (256, 256)), axis = 0)\n",
    "        if count == 0:\n",
    "            imgs = img_scaled\n",
    "        else:\n",
    "            imgs = np.vstack((imgs, img_scaled))\n",
    "        count += 1\n",
    "                             \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "images_shrunk = rescale_imgs(images_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print (images_shrunk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(images, labels, ratio = 0.5):\n",
    "    split = round(ratio*images.shape[0])\n",
    "    \n",
    "    train_x = images[ :split, :]\n",
    "    test_x = images[split:, :]\n",
    "    train_y = labels[ :split]\n",
    "    test_y = labels[split:]\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = format_data(images_shrunk, labels_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs = np.reshape(images_shrunk, (-1, images_shrunk.shape[1], images_shrunk.shape[2]))\n",
    "\n",
    "#plt.figure(figsize=(12, 12))\n",
    "#for n in range(0, 16):\n",
    "    #plt.subplot(4, 4, 1 + n)\n",
    "    #plt.imshow(stretch(imgs[-n-1,:,:]), cmap='viridis', shape=(135, 135))\n",
    "    #plt.axis('off')\n",
    "    #plt.title(labels[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stretch = vis.AsinhStretch(1e-1) + vis.MinMaxInterval()\n",
    "\n",
    "#images_s = np.zeros((images_shrunk.shape[0], images_shrunk.shape[1], images_shrunk.shape[2]))\n",
    "\n",
    "#for i, images in enumerate(images_shrunk):\n",
    "    #images_s[i, :, :] = stretch(images_shrunk[i, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(images, labels):\n",
    "\n",
    "    batch_size = 20\n",
    "    samples = np.asarray(images).shape[0]\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "            rotation_range=180,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip =True,\n",
    "            fill_mode = \"nearest\")\n",
    "\n",
    "    x = images.reshape((-1, images.shape[1],images.shape[2], 1))\n",
    "\n",
    "    # the .flow() command below generates batches of randomly transformed images\n",
    "    # and saves the results to the `preview/` directory\n",
    "    gen = datagen.flow(x, np.asarray(labels), batch_size=batch_size)\n",
    "\n",
    "    data_mult = 100\n",
    "\n",
    "    pro_images = np.zeros((images.shape[0]*data_mult, images.shape[1], images.shape[2], 1))\n",
    "    pro_labels = np.zeros((labels.shape[0]*data_mult))\n",
    "    \n",
    "    for e in range(1, data_mult+1):\n",
    "        batch = 1\n",
    "        b = batch_size\n",
    "        b_start = samples*(e-1)\n",
    "\n",
    "        for X_batch, Y_batch in gen:\n",
    "            if batch < (samples/b):\n",
    "                pro_images[b_start+b*(batch-1):b_start+batch*b, :, :, :] = X_batch\n",
    "                pro_labels[b_start+b*(batch-1):b_start+batch*b] = Y_batch\n",
    "\n",
    "            else: \n",
    "                pro_images[b_start+b*(batch-1):b_start+b*(batch-1) + X_batch.shape[0]%b, :, :, :] = X_batch\n",
    "                pro_labels[b_start+b*(batch-1):b_start+b*(batch-1) + X_batch.shape[0]%b] = Y_batch\n",
    "                break\n",
    "\n",
    "\n",
    "            batch += 1\n",
    "        print(e)\n",
    "        \n",
    "    return pro_images, pro_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pro_train_x, pro_train_y = data_gen(train_x, train_y)\n",
    "#pro_test_x, pro_test_y  = data_gen(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pro_train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bf01e9489cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpro_train_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpro_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpro_train_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_train_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_train_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpro_test_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpro_test_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpro_test_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_test_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpro_test_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pro_train_x' is not defined"
     ]
    }
   ],
   "source": [
    "#pro_train_x = np.reshape(pro_train_x, (pro_train_x.shape[0], pro_train_x.shape[1], pro_train_x.shape[2]))\n",
    "#pro_test_x = np.reshape(pro_test_x, (pro_test_x.shape[0], pro_test_x.shape[1], pro_test_x.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs = np.reshape(pro_images, (-1, pro_images.shape[1], pro_images.shape[2]))\n",
    "\n",
    "#for n in range(0, imgs.shape[0]):\n",
    "   #plt.imshow(imgs[n,:,:], cmap='gray', shape=(89, 89))\n",
    "   #print (n)\n",
    "   #print (pro_labels[n])\n",
    "   #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_x.dat', 'wb') as f:\n",
    "    pickle.dump(train_x, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_x.dat', 'wb') as f:\n",
    "    pickle.dump(test_x, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_y.dat', 'wb') as f:\n",
    "    pickle.dump(train_y, f, protocol=-1)    \n",
    "\n",
    "with open('test_y.dat', 'wb') as f:\n",
    "    pickle.dump(test_y, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
