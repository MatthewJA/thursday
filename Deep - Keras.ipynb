{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import *\n",
    "import os\n",
    "import h5py\n",
    "import keras as k\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"C:\\Users\\fires\\Desktop\\CSIRO\\thursday\\HOG\\images.dat\",'rb')\n",
    "images = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open(r\"C:\\Users\\fires\\Desktop\\CSIRO\\thursday\\HOG\\labels.dat\",'rb')\n",
    "labels = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(-1, 89*89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance classes\n",
    "def bal_classes(images, labels):\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    \n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == False:\n",
    "            class1.append(i)\n",
    "    \n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == True:\n",
    "            class2.append(i)\n",
    "    \n",
    "    if len(class2) > len(class1):\n",
    "        class2 = np.asarray(class2[:len(class1)])\n",
    "    \n",
    "    elif len(class2) < len(class1):\n",
    "        class1 = np.asarray(class1[:len(class2)])\n",
    "        \n",
    "    images1 = images[class1, :] \n",
    "    images2 = images[class2, :]\n",
    "    labels1 = labels[class1,]\n",
    "    labels2 = labels[class2,]\n",
    "    \n",
    "    print (labels2.shape)\n",
    "    \n",
    "    images_st = np.vstack((images1, images2))\n",
    "    labels_st =  np.concatenate((labels1, labels2), axis=0)              \n",
    "        \n",
    "    images_s, labels_s = shuffle(np.asarray(images_st), np.asarray(labels_st), random_state = 0)    \n",
    "        \n",
    "    return images_s, labels_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1216,)\n"
     ]
    }
   ],
   "source": [
    "images_p, labels_p = bal_classes(np.asarray(images), np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(images, labels, ratio = 0.5):\n",
    "    split = round(ratio*images.shape[0])\n",
    "    \n",
    "    train_x = images[ :split, :]\n",
    "    test_x = images[split:, :]\n",
    "    train_y = labels[ :split]\n",
    "    test_y = labels[split:]\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = format_data(images_p, labels_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "train_y = np_utils.to_categorical(train_y, 2)\n",
    "test_y = np_utils.to_categorical(test_y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model attributes\n",
    "\n",
    "batch_size = 20\n",
    "nb_classes = output_dims = 2\n",
    "nb_epoch = 400\n",
    "input_dim = 7921\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim = input_dim, activation = 'softmax'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=output_dims, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1216 samples, validate on 1216 samples\n",
      "Epoch 1/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6934 - acc: 0.4803 - val_loss: 0.6932 - val_acc: 0.4885\n",
      "Epoch 2/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6931 - acc: 0.5058 - val_loss: 0.6933 - val_acc: 0.4885\n",
      "Epoch 3/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6931 - acc: 0.5090 - val_loss: 0.6934 - val_acc: 0.4885\n",
      "Epoch 4/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6930 - acc: 0.5107 - val_loss: 0.6934 - val_acc: 0.4885\n",
      "Epoch 5/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6928 - acc: 0.5115 - val_loss: 0.6934 - val_acc: 0.4885\n",
      "Epoch 6/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6927 - acc: 0.5115 - val_loss: 0.6936 - val_acc: 0.4885\n",
      "Epoch 7/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6928 - acc: 0.5115 - val_loss: 0.6936 - val_acc: 0.4885\n",
      "Epoch 8/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6928 - acc: 0.5115 - val_loss: 0.6936 - val_acc: 0.4885\n",
      "Epoch 9/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6927 - acc: 0.5115 - val_loss: 0.6937 - val_acc: 0.4885\n",
      "Epoch 10/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5115 - val_loss: 0.6936 - val_acc: 0.4885\n",
      "Epoch 11/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6928 - acc: 0.5115 - val_loss: 0.6937 - val_acc: 0.4885\n",
      "Epoch 12/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6924 - acc: 0.5115 - val_loss: 0.6937 - val_acc: 0.4885\n",
      "Epoch 13/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6925 - acc: 0.5115 - val_loss: 0.6936 - val_acc: 0.4885\n",
      "Epoch 14/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6924 - acc: 0.5115 - val_loss: 0.6935 - val_acc: 0.4885\n",
      "Epoch 15/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6926 - acc: 0.5115 - val_loss: 0.6935 - val_acc: 0.4885\n",
      "Epoch 16/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6923 - acc: 0.5115 - val_loss: 0.6933 - val_acc: 0.4885\n",
      "Epoch 17/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6924 - acc: 0.5115 - val_loss: 0.6933 - val_acc: 0.4885\n",
      "Epoch 18/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6924 - acc: 0.5115 - val_loss: 0.6934 - val_acc: 0.4885\n",
      "Epoch 19/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6921 - acc: 0.5123 - val_loss: 0.6933 - val_acc: 0.4885\n",
      "Epoch 20/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6921 - acc: 0.5148 - val_loss: 0.6932 - val_acc: 0.4918\n",
      "Epoch 21/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6922 - acc: 0.5189 - val_loss: 0.6930 - val_acc: 0.4934\n",
      "Epoch 22/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6919 - acc: 0.5148 - val_loss: 0.6931 - val_acc: 0.4926\n",
      "Epoch 23/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6918 - acc: 0.5189 - val_loss: 0.6930 - val_acc: 0.4934\n",
      "Epoch 24/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6918 - acc: 0.5206 - val_loss: 0.6930 - val_acc: 0.4934\n",
      "Epoch 25/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6917 - acc: 0.5197 - val_loss: 0.6929 - val_acc: 0.4934\n",
      "Epoch 26/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6915 - acc: 0.5288 - val_loss: 0.6928 - val_acc: 0.4934\n",
      "Epoch 27/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6912 - acc: 0.5304 - val_loss: 0.6926 - val_acc: 0.4967\n",
      "Epoch 28/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6913 - acc: 0.5255 - val_loss: 0.6925 - val_acc: 0.4984\n",
      "Epoch 29/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6911 - acc: 0.5321 - val_loss: 0.6924 - val_acc: 0.5033\n",
      "Epoch 30/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6911 - acc: 0.5288 - val_loss: 0.6924 - val_acc: 0.5008\n",
      "Epoch 31/400\n",
      "1216/1216 [==============================] - 3s 3ms/step - loss: 0.6907 - acc: 0.5329 - val_loss: 0.6922 - val_acc: 0.5066\n",
      "Epoch 32/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6907 - acc: 0.5345 - val_loss: 0.6921 - val_acc: 0.5066\n",
      "Epoch 33/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6907 - acc: 0.5378 - val_loss: 0.6918 - val_acc: 0.5123\n",
      "Epoch 34/400\n",
      "1216/1216 [==============================] - 3s 3ms/step - loss: 0.6901 - acc: 0.5461 - val_loss: 0.6916 - val_acc: 0.5140\n",
      "Epoch 35/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6898 - acc: 0.5428 - val_loss: 0.6916 - val_acc: 0.5140\n",
      "Epoch 36/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6896 - acc: 0.5428 - val_loss: 0.6913 - val_acc: 0.5156\n",
      "Epoch 37/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6896 - acc: 0.5518 - val_loss: 0.6911 - val_acc: 0.5197\n",
      "Epoch 38/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6896 - acc: 0.5526 - val_loss: 0.6908 - val_acc: 0.5247\n",
      "Epoch 39/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6894 - acc: 0.5502 - val_loss: 0.6907 - val_acc: 0.5206\n",
      "Epoch 40/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6884 - acc: 0.5567 - val_loss: 0.6904 - val_acc: 0.5255\n",
      "Epoch 41/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6881 - acc: 0.5600 - val_loss: 0.6903 - val_acc: 0.5255\n",
      "Epoch 42/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6878 - acc: 0.5609 - val_loss: 0.6900 - val_acc: 0.5288\n",
      "Epoch 43/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6877 - acc: 0.5715 - val_loss: 0.6896 - val_acc: 0.5378\n",
      "Epoch 44/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6870 - acc: 0.5683 - val_loss: 0.6894 - val_acc: 0.5354\n",
      "Epoch 45/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6871 - acc: 0.5765 - val_loss: 0.6891 - val_acc: 0.5395\n",
      "Epoch 46/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6865 - acc: 0.5641 - val_loss: 0.6889 - val_acc: 0.5395\n",
      "Epoch 47/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6859 - acc: 0.5666 - val_loss: 0.6885 - val_acc: 0.5395\n",
      "Epoch 48/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6855 - acc: 0.5789 - val_loss: 0.6882 - val_acc: 0.5395\n",
      "Epoch 49/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6847 - acc: 0.5798 - val_loss: 0.6877 - val_acc: 0.5428\n",
      "Epoch 50/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6845 - acc: 0.6003 - val_loss: 0.6873 - val_acc: 0.5477\n",
      "Epoch 51/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6839 - acc: 0.5839 - val_loss: 0.6870 - val_acc: 0.5469\n",
      "Epoch 52/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6837 - acc: 0.5822 - val_loss: 0.6865 - val_acc: 0.5493\n",
      "Epoch 53/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6828 - acc: 0.5913 - val_loss: 0.6860 - val_acc: 0.5518\n",
      "Epoch 54/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6826 - acc: 0.5855 - val_loss: 0.6856 - val_acc: 0.5518\n",
      "Epoch 55/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6823 - acc: 0.6012 - val_loss: 0.6852 - val_acc: 0.5535\n",
      "Epoch 56/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6820 - acc: 0.6020 - val_loss: 0.6847 - val_acc: 0.5567\n",
      "Epoch 57/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6805 - acc: 0.5896 - val_loss: 0.6843 - val_acc: 0.5551\n",
      "Epoch 58/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6804 - acc: 0.5880 - val_loss: 0.6840 - val_acc: 0.5543\n",
      "Epoch 59/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6787 - acc: 0.6012 - val_loss: 0.6832 - val_acc: 0.5567\n",
      "Epoch 60/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6782 - acc: 0.6176 - val_loss: 0.6826 - val_acc: 0.5633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6775 - acc: 0.6135 - val_loss: 0.6820 - val_acc: 0.5650\n",
      "Epoch 62/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6766 - acc: 0.6151 - val_loss: 0.6814 - val_acc: 0.5691\n",
      "Epoch 63/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6763 - acc: 0.6283 - val_loss: 0.6809 - val_acc: 0.5674\n",
      "Epoch 64/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6758 - acc: 0.6176 - val_loss: 0.6802 - val_acc: 0.5748\n",
      "Epoch 65/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6752 - acc: 0.6324 - val_loss: 0.6796 - val_acc: 0.5789\n",
      "Epoch 66/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6745 - acc: 0.6176 - val_loss: 0.6792 - val_acc: 0.5666\n",
      "Epoch 67/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6737 - acc: 0.6382 - val_loss: 0.6783 - val_acc: 0.5880\n",
      "Epoch 68/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6716 - acc: 0.6447 - val_loss: 0.6777 - val_acc: 0.5806\n",
      "Epoch 69/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6704 - acc: 0.6521 - val_loss: 0.6769 - val_acc: 0.5888\n",
      "Epoch 70/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6706 - acc: 0.6357 - val_loss: 0.6763 - val_acc: 0.5863\n",
      "Epoch 71/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6690 - acc: 0.6464 - val_loss: 0.6756 - val_acc: 0.5888\n",
      "Epoch 72/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6677 - acc: 0.6472 - val_loss: 0.6748 - val_acc: 0.5905\n",
      "Epoch 73/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6669 - acc: 0.6604 - val_loss: 0.6738 - val_acc: 0.6110\n",
      "Epoch 74/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6656 - acc: 0.6521 - val_loss: 0.6732 - val_acc: 0.6003\n",
      "Epoch 75/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6639 - acc: 0.6604 - val_loss: 0.6723 - val_acc: 0.6094\n",
      "Epoch 76/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6624 - acc: 0.6620 - val_loss: 0.6714 - val_acc: 0.6143\n",
      "Epoch 77/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6625 - acc: 0.6620 - val_loss: 0.6708 - val_acc: 0.6069\n",
      "Epoch 78/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6609 - acc: 0.6653 - val_loss: 0.6698 - val_acc: 0.6176\n",
      "Epoch 79/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6608 - acc: 0.6637 - val_loss: 0.6690 - val_acc: 0.6135\n",
      "Epoch 80/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6598 - acc: 0.6628 - val_loss: 0.6680 - val_acc: 0.6234\n",
      "Epoch 81/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6583 - acc: 0.6719 - val_loss: 0.6670 - val_acc: 0.6250\n",
      "Epoch 82/400\n",
      "1216/1216 [==============================] - 3s 3ms/step - loss: 0.6553 - acc: 0.6776 - val_loss: 0.6662 - val_acc: 0.6242\n",
      "Epoch 83/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6563 - acc: 0.6653 - val_loss: 0.6655 - val_acc: 0.6242\n",
      "Epoch 84/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6547 - acc: 0.6727 - val_loss: 0.6645 - val_acc: 0.6250\n",
      "Epoch 85/400\n",
      "1216/1216 [==============================] - 3s 3ms/step - loss: 0.6530 - acc: 0.6768 - val_loss: 0.6636 - val_acc: 0.6250\n",
      "Epoch 86/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.6533 - acc: 0.6711 - val_loss: 0.6626 - val_acc: 0.6258\n",
      "Epoch 87/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6506 - acc: 0.6859 - val_loss: 0.6618 - val_acc: 0.6242\n",
      "Epoch 88/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6492 - acc: 0.6859 - val_loss: 0.6609 - val_acc: 0.6242\n",
      "Epoch 89/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6466 - acc: 0.6924 - val_loss: 0.6598 - val_acc: 0.6258\n",
      "Epoch 90/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6465 - acc: 0.6916 - val_loss: 0.6588 - val_acc: 0.6291\n",
      "Epoch 91/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6466 - acc: 0.6694 - val_loss: 0.6580 - val_acc: 0.6258\n",
      "Epoch 92/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6445 - acc: 0.6867 - val_loss: 0.6567 - val_acc: 0.6324\n",
      "Epoch 93/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6433 - acc: 0.6850 - val_loss: 0.6559 - val_acc: 0.6324\n",
      "Epoch 94/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6406 - acc: 0.6834 - val_loss: 0.6548 - val_acc: 0.6340\n",
      "Epoch 95/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6394 - acc: 0.7007 - val_loss: 0.6536 - val_acc: 0.6390\n",
      "Epoch 96/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6367 - acc: 0.7048 - val_loss: 0.6528 - val_acc: 0.6340\n",
      "Epoch 97/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6376 - acc: 0.6933 - val_loss: 0.6517 - val_acc: 0.6365\n",
      "Epoch 98/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6329 - acc: 0.7097 - val_loss: 0.6505 - val_acc: 0.6423\n",
      "Epoch 99/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6349 - acc: 0.6900 - val_loss: 0.6499 - val_acc: 0.6340\n",
      "Epoch 100/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6323 - acc: 0.7023 - val_loss: 0.6485 - val_acc: 0.6423\n",
      "Epoch 101/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6314 - acc: 0.7105 - val_loss: 0.6475 - val_acc: 0.6414\n",
      "Epoch 102/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6304 - acc: 0.6957 - val_loss: 0.6465 - val_acc: 0.6431\n",
      "Epoch 103/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6259 - acc: 0.7262 - val_loss: 0.6449 - val_acc: 0.6538\n",
      "Epoch 104/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6271 - acc: 0.7113 - val_loss: 0.6441 - val_acc: 0.6472\n",
      "Epoch 105/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6244 - acc: 0.7204 - val_loss: 0.6433 - val_acc: 0.6456\n",
      "Epoch 106/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6203 - acc: 0.7286 - val_loss: 0.6419 - val_acc: 0.6480\n",
      "Epoch 107/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6228 - acc: 0.7122 - val_loss: 0.6411 - val_acc: 0.6497\n",
      "Epoch 108/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6198 - acc: 0.7155 - val_loss: 0.6400 - val_acc: 0.6497\n",
      "Epoch 109/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6201 - acc: 0.7179 - val_loss: 0.6389 - val_acc: 0.6521\n",
      "Epoch 110/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6173 - acc: 0.7336 - val_loss: 0.6381 - val_acc: 0.6497\n",
      "Epoch 111/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6166 - acc: 0.7220 - val_loss: 0.6368 - val_acc: 0.6546\n",
      "Epoch 112/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6147 - acc: 0.7220 - val_loss: 0.6360 - val_acc: 0.6513\n",
      "Epoch 113/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6115 - acc: 0.7294 - val_loss: 0.6345 - val_acc: 0.6579\n",
      "Epoch 114/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6124 - acc: 0.7311 - val_loss: 0.6339 - val_acc: 0.6521\n",
      "Epoch 115/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6090 - acc: 0.7360 - val_loss: 0.6327 - val_acc: 0.6571\n",
      "Epoch 116/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6072 - acc: 0.7467 - val_loss: 0.6313 - val_acc: 0.6637\n",
      "Epoch 117/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.6062 - acc: 0.7327 - val_loss: 0.6304 - val_acc: 0.6595\n",
      "Epoch 118/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6027 - acc: 0.7434 - val_loss: 0.6293 - val_acc: 0.6620\n",
      "Epoch 119/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.6005 - acc: 0.7368 - val_loss: 0.6283 - val_acc: 0.6620\n",
      "Epoch 120/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5999 - acc: 0.7525 - val_loss: 0.6267 - val_acc: 0.6719\n",
      "Epoch 121/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5973 - acc: 0.7459 - val_loss: 0.6259 - val_acc: 0.6661\n",
      "Epoch 122/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5952 - acc: 0.7566 - val_loss: 0.6249 - val_acc: 0.6678\n",
      "Epoch 123/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5987 - acc: 0.7204 - val_loss: 0.6240 - val_acc: 0.6653\n",
      "Epoch 124/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5931 - acc: 0.7533 - val_loss: 0.6227 - val_acc: 0.6727\n",
      "Epoch 125/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5945 - acc: 0.7615 - val_loss: 0.6219 - val_acc: 0.6686\n",
      "Epoch 126/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5927 - acc: 0.7360 - val_loss: 0.6213 - val_acc: 0.6637\n",
      "Epoch 127/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5906 - acc: 0.7377 - val_loss: 0.6197 - val_acc: 0.6743\n",
      "Epoch 128/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5833 - acc: 0.7722 - val_loss: 0.6188 - val_acc: 0.6719\n",
      "Epoch 129/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5868 - acc: 0.7574 - val_loss: 0.6175 - val_acc: 0.6760\n",
      "Epoch 130/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5812 - acc: 0.7459 - val_loss: 0.6169 - val_acc: 0.6727\n",
      "Epoch 131/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5832 - acc: 0.7607 - val_loss: 0.6154 - val_acc: 0.6785\n",
      "Epoch 132/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5840 - acc: 0.7492 - val_loss: 0.6146 - val_acc: 0.6768\n",
      "Epoch 133/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5805 - acc: 0.7541 - val_loss: 0.6135 - val_acc: 0.6809\n",
      "Epoch 134/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5789 - acc: 0.7632 - val_loss: 0.6124 - val_acc: 0.6817\n",
      "Epoch 135/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5772 - acc: 0.7558 - val_loss: 0.6122 - val_acc: 0.6719\n",
      "Epoch 136/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5762 - acc: 0.7714 - val_loss: 0.6104 - val_acc: 0.6859\n",
      "Epoch 137/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5744 - acc: 0.7706 - val_loss: 0.6095 - val_acc: 0.6842\n",
      "Epoch 138/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5694 - acc: 0.7747 - val_loss: 0.6085 - val_acc: 0.6867\n",
      "Epoch 139/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5698 - acc: 0.7656 - val_loss: 0.6074 - val_acc: 0.6908\n",
      "Epoch 140/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5731 - acc: 0.7607 - val_loss: 0.6065 - val_acc: 0.6933\n",
      "Epoch 141/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5728 - acc: 0.7656 - val_loss: 0.6057 - val_acc: 0.6875\n",
      "Epoch 142/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5623 - acc: 0.7788 - val_loss: 0.6051 - val_acc: 0.6817\n",
      "Epoch 143/400\n",
      "1216/1216 [==============================] - 3s 3ms/step - loss: 0.5661 - acc: 0.7607 - val_loss: 0.6038 - val_acc: 0.6916\n",
      "Epoch 144/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5603 - acc: 0.7730 - val_loss: 0.6027 - val_acc: 0.6974\n",
      "Epoch 145/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5592 - acc: 0.7730 - val_loss: 0.6021 - val_acc: 0.6891\n",
      "Epoch 146/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5604 - acc: 0.7697 - val_loss: 0.6008 - val_acc: 0.6974\n",
      "Epoch 147/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5559 - acc: 0.7903 - val_loss: 0.5999 - val_acc: 0.6974\n",
      "Epoch 148/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5636 - acc: 0.7623 - val_loss: 0.5993 - val_acc: 0.6933\n",
      "Epoch 149/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5637 - acc: 0.7574 - val_loss: 0.5979 - val_acc: 0.7023\n",
      "Epoch 150/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5552 - acc: 0.7878 - val_loss: 0.5973 - val_acc: 0.6982\n",
      "Epoch 151/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5503 - acc: 0.7878 - val_loss: 0.5963 - val_acc: 0.6990\n",
      "Epoch 152/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5516 - acc: 0.7903 - val_loss: 0.5954 - val_acc: 0.7007\n",
      "Epoch 153/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5520 - acc: 0.7837 - val_loss: 0.5944 - val_acc: 0.7023\n",
      "Epoch 154/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5408 - acc: 0.8076 - val_loss: 0.5937 - val_acc: 0.6990\n",
      "Epoch 155/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5461 - acc: 0.7944 - val_loss: 0.5930 - val_acc: 0.6990\n",
      "Epoch 156/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5418 - acc: 0.7878 - val_loss: 0.5916 - val_acc: 0.7072\n",
      "Epoch 157/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.5422 - acc: 0.7944 - val_loss: 0.5907 - val_acc: 0.7064\n",
      "Epoch 158/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5444 - acc: 0.7722 - val_loss: 0.5900 - val_acc: 0.7072\n",
      "Epoch 159/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5421 - acc: 0.7862 - val_loss: 0.5892 - val_acc: 0.7064\n",
      "Epoch 160/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5412 - acc: 0.7837 - val_loss: 0.5887 - val_acc: 0.7015\n",
      "Epoch 161/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5376 - acc: 0.7985 - val_loss: 0.5877 - val_acc: 0.7056\n",
      "Epoch 162/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5386 - acc: 0.7944 - val_loss: 0.5867 - val_acc: 0.7064\n",
      "Epoch 163/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.5327 - acc: 0.7878 - val_loss: 0.5858 - val_acc: 0.7081\n",
      "Epoch 164/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5352 - acc: 0.7887 - val_loss: 0.5854 - val_acc: 0.7064\n",
      "Epoch 165/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5308 - acc: 0.8018 - val_loss: 0.5844 - val_acc: 0.7064\n",
      "Epoch 166/400\n",
      "1216/1216 [==============================] - 1s 1ms/step - loss: 0.5281 - acc: 0.8026 - val_loss: 0.5832 - val_acc: 0.7130\n",
      "Epoch 167/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5297 - acc: 0.7977 - val_loss: 0.5826 - val_acc: 0.7105\n",
      "Epoch 168/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5221 - acc: 0.7936 - val_loss: 0.5822 - val_acc: 0.7064\n",
      "Epoch 169/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5243 - acc: 0.8051 - val_loss: 0.5807 - val_acc: 0.7179\n",
      "Epoch 170/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5257 - acc: 0.8035 - val_loss: 0.5800 - val_acc: 0.7163\n",
      "Epoch 171/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5229 - acc: 0.8010 - val_loss: 0.5792 - val_acc: 0.7163\n",
      "Epoch 172/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5180 - acc: 0.8183 - val_loss: 0.5788 - val_acc: 0.7130\n",
      "Epoch 173/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5173 - acc: 0.8092 - val_loss: 0.5780 - val_acc: 0.7155\n",
      "Epoch 174/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5239 - acc: 0.7944 - val_loss: 0.5774 - val_acc: 0.7122\n",
      "Epoch 175/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5101 - acc: 0.8125 - val_loss: 0.5762 - val_acc: 0.7212\n",
      "Epoch 176/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5109 - acc: 0.8191 - val_loss: 0.5749 - val_acc: 0.7352\n",
      "Epoch 177/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5078 - acc: 0.8125 - val_loss: 0.5744 - val_acc: 0.7278\n",
      "Epoch 178/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5110 - acc: 0.8150 - val_loss: 0.5740 - val_acc: 0.7253\n",
      "Epoch 179/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5047 - acc: 0.8281 - val_loss: 0.5728 - val_acc: 0.7344\n",
      "Epoch 180/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5081 - acc: 0.8051 - val_loss: 0.5723 - val_acc: 0.7294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5048 - acc: 0.8166 - val_loss: 0.5716 - val_acc: 0.7294\n",
      "Epoch 182/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5041 - acc: 0.8109 - val_loss: 0.5718 - val_acc: 0.7179\n",
      "Epoch 183/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5076 - acc: 0.8133 - val_loss: 0.5705 - val_acc: 0.7270\n",
      "Epoch 184/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5043 - acc: 0.7977 - val_loss: 0.5697 - val_acc: 0.7311\n",
      "Epoch 185/400\n",
      "1216/1216 [==============================] - 1s 1ms/step - loss: 0.4980 - acc: 0.8339 - val_loss: 0.5689 - val_acc: 0.7336\n",
      "Epoch 186/400\n",
      "1216/1216 [==============================] - 1s 1ms/step - loss: 0.4993 - acc: 0.8281 - val_loss: 0.5681 - val_acc: 0.7377\n",
      "Epoch 187/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4911 - acc: 0.8372 - val_loss: 0.5673 - val_acc: 0.7385\n",
      "Epoch 188/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4943 - acc: 0.8298 - val_loss: 0.5663 - val_acc: 0.7426\n",
      "Epoch 189/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.5000 - acc: 0.8133 - val_loss: 0.5661 - val_acc: 0.7393\n",
      "Epoch 190/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4987 - acc: 0.8035 - val_loss: 0.5658 - val_acc: 0.7344\n",
      "Epoch 191/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4931 - acc: 0.8043 - val_loss: 0.5643 - val_acc: 0.7451\n",
      "Epoch 192/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4908 - acc: 0.8273 - val_loss: 0.5638 - val_acc: 0.7459\n",
      "Epoch 193/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4874 - acc: 0.8298 - val_loss: 0.5640 - val_acc: 0.7352\n",
      "Epoch 194/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4877 - acc: 0.8183 - val_loss: 0.5629 - val_acc: 0.7434\n",
      "Epoch 195/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4872 - acc: 0.8158 - val_loss: 0.5624 - val_acc: 0.7434\n",
      "Epoch 196/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4871 - acc: 0.8257 - val_loss: 0.5616 - val_acc: 0.7426\n",
      "Epoch 197/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4805 - acc: 0.8248 - val_loss: 0.5612 - val_acc: 0.7434\n",
      "Epoch 198/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4789 - acc: 0.8322 - val_loss: 0.5606 - val_acc: 0.7434\n",
      "Epoch 199/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4870 - acc: 0.8100 - val_loss: 0.5602 - val_acc: 0.7434\n",
      "Epoch 200/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4817 - acc: 0.8191 - val_loss: 0.5597 - val_acc: 0.7434\n",
      "Epoch 201/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4704 - acc: 0.8380 - val_loss: 0.5587 - val_acc: 0.7484\n",
      "Epoch 202/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4748 - acc: 0.8306 - val_loss: 0.5582 - val_acc: 0.7484\n",
      "Epoch 203/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4748 - acc: 0.8331 - val_loss: 0.5574 - val_acc: 0.7492\n",
      "Epoch 204/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4726 - acc: 0.8470 - val_loss: 0.5579 - val_acc: 0.7401\n",
      "Epoch 205/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4763 - acc: 0.8298 - val_loss: 0.5565 - val_acc: 0.7492\n",
      "Epoch 206/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4670 - acc: 0.8446 - val_loss: 0.5552 - val_acc: 0.7500\n",
      "Epoch 207/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4747 - acc: 0.8207 - val_loss: 0.5553 - val_acc: 0.7508\n",
      "Epoch 208/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4619 - acc: 0.8388 - val_loss: 0.5550 - val_acc: 0.7484\n",
      "Epoch 209/400\n",
      "1216/1216 [==============================] - 3s 3ms/step - loss: 0.4692 - acc: 0.8314 - val_loss: 0.5534 - val_acc: 0.7533\n",
      "Epoch 210/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4632 - acc: 0.8405 - val_loss: 0.5535 - val_acc: 0.7500\n",
      "Epoch 211/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4638 - acc: 0.8437 - val_loss: 0.5533 - val_acc: 0.7508\n",
      "Epoch 212/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4729 - acc: 0.8265 - val_loss: 0.5522 - val_acc: 0.7541\n",
      "Epoch 213/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4611 - acc: 0.8421 - val_loss: 0.5521 - val_acc: 0.7516\n",
      "Epoch 214/400\n",
      "1216/1216 [==============================] - 3s 3ms/step - loss: 0.4593 - acc: 0.8331 - val_loss: 0.5508 - val_acc: 0.7558\n",
      "Epoch 215/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4585 - acc: 0.8380 - val_loss: 0.5511 - val_acc: 0.7525\n",
      "Epoch 216/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4581 - acc: 0.8446 - val_loss: 0.5509 - val_acc: 0.7492\n",
      "Epoch 217/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4544 - acc: 0.8421 - val_loss: 0.5500 - val_acc: 0.7549\n",
      "Epoch 218/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4585 - acc: 0.8437 - val_loss: 0.5495 - val_acc: 0.7533\n",
      "Epoch 219/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4627 - acc: 0.8298 - val_loss: 0.5497 - val_acc: 0.7500\n",
      "Epoch 220/400\n",
      "1216/1216 [==============================] - 3s 3ms/step - loss: 0.4519 - acc: 0.8503 - val_loss: 0.5487 - val_acc: 0.7549\n",
      "Epoch 221/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4489 - acc: 0.8602 - val_loss: 0.5483 - val_acc: 0.7549\n",
      "Epoch 222/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4553 - acc: 0.8396 - val_loss: 0.5476 - val_acc: 0.7541\n",
      "Epoch 223/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4553 - acc: 0.8372 - val_loss: 0.5471 - val_acc: 0.7558\n",
      "Epoch 224/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4517 - acc: 0.8462 - val_loss: 0.5472 - val_acc: 0.7541\n",
      "Epoch 225/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4435 - acc: 0.8610 - val_loss: 0.5458 - val_acc: 0.7623\n",
      "Epoch 226/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4465 - acc: 0.8347 - val_loss: 0.5455 - val_acc: 0.7599\n",
      "Epoch 227/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4453 - acc: 0.8487 - val_loss: 0.5456 - val_acc: 0.7558\n",
      "Epoch 228/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.4378 - acc: 0.8643 - val_loss: 0.5455 - val_acc: 0.7549\n",
      "Epoch 229/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4471 - acc: 0.8470 - val_loss: 0.5447 - val_acc: 0.7566\n",
      "Epoch 230/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4422 - acc: 0.8396 - val_loss: 0.5448 - val_acc: 0.7549\n",
      "Epoch 231/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4411 - acc: 0.8421 - val_loss: 0.5447 - val_acc: 0.7541\n",
      "Epoch 232/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4420 - acc: 0.8380 - val_loss: 0.5435 - val_acc: 0.7566\n",
      "Epoch 233/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4355 - acc: 0.8520 - val_loss: 0.5432 - val_acc: 0.7582\n",
      "Epoch 234/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4414 - acc: 0.8479 - val_loss: 0.5421 - val_acc: 0.7656\n",
      "Epoch 235/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4356 - acc: 0.8503 - val_loss: 0.5427 - val_acc: 0.7558\n",
      "Epoch 236/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4334 - acc: 0.8454 - val_loss: 0.5427 - val_acc: 0.7541\n",
      "Epoch 237/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4198 - acc: 0.8635 - val_loss: 0.5419 - val_acc: 0.7574\n",
      "Epoch 238/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4282 - acc: 0.8577 - val_loss: 0.5415 - val_acc: 0.7582\n",
      "Epoch 239/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4265 - acc: 0.8487 - val_loss: 0.5420 - val_acc: 0.7525\n",
      "Epoch 240/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4260 - acc: 0.8577 - val_loss: 0.5402 - val_acc: 0.7648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4224 - acc: 0.8569 - val_loss: 0.5397 - val_acc: 0.7656\n",
      "Epoch 242/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4315 - acc: 0.8503 - val_loss: 0.5400 - val_acc: 0.7590\n",
      "Epoch 243/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4298 - acc: 0.8437 - val_loss: 0.5393 - val_acc: 0.7632\n",
      "Epoch 244/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4192 - acc: 0.8643 - val_loss: 0.5383 - val_acc: 0.7681\n",
      "Epoch 245/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4210 - acc: 0.8676 - val_loss: 0.5386 - val_acc: 0.7640\n",
      "Epoch 246/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4188 - acc: 0.8651 - val_loss: 0.5377 - val_acc: 0.7673\n",
      "Epoch 247/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4179 - acc: 0.8594 - val_loss: 0.5380 - val_acc: 0.7640\n",
      "Epoch 248/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4139 - acc: 0.8676 - val_loss: 0.5376 - val_acc: 0.7656\n",
      "Epoch 249/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4090 - acc: 0.8651 - val_loss: 0.5369 - val_acc: 0.7673\n",
      "Epoch 250/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4136 - acc: 0.8643 - val_loss: 0.5369 - val_acc: 0.7656\n",
      "Epoch 251/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4086 - acc: 0.8553 - val_loss: 0.5371 - val_acc: 0.7599\n",
      "Epoch 252/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4132 - acc: 0.8594 - val_loss: 0.5371 - val_acc: 0.7590\n",
      "Epoch 253/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4120 - acc: 0.8618 - val_loss: 0.5366 - val_acc: 0.7590\n",
      "Epoch 254/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4117 - acc: 0.8586 - val_loss: 0.5351 - val_acc: 0.7706\n",
      "Epoch 255/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4066 - acc: 0.8701 - val_loss: 0.5354 - val_acc: 0.7656\n",
      "Epoch 256/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.4088 - acc: 0.8569 - val_loss: 0.5360 - val_acc: 0.7590\n",
      "Epoch 257/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4036 - acc: 0.8651 - val_loss: 0.5350 - val_acc: 0.7648\n",
      "Epoch 258/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4003 - acc: 0.8709 - val_loss: 0.5349 - val_acc: 0.7623\n",
      "Epoch 259/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3977 - acc: 0.8725 - val_loss: 0.5332 - val_acc: 0.7714\n",
      "Epoch 260/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3971 - acc: 0.8676 - val_loss: 0.5336 - val_acc: 0.7689\n",
      "Epoch 261/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3982 - acc: 0.8643 - val_loss: 0.5336 - val_acc: 0.7656\n",
      "Epoch 262/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4017 - acc: 0.8643 - val_loss: 0.5335 - val_acc: 0.7664\n",
      "Epoch 263/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4030 - acc: 0.8660 - val_loss: 0.5327 - val_acc: 0.7697\n",
      "Epoch 264/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3916 - acc: 0.8725 - val_loss: 0.5324 - val_acc: 0.7689\n",
      "Epoch 265/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3941 - acc: 0.8725 - val_loss: 0.5324 - val_acc: 0.7681\n",
      "Epoch 266/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.4009 - acc: 0.8536 - val_loss: 0.5338 - val_acc: 0.7541\n",
      "Epoch 267/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3978 - acc: 0.8618 - val_loss: 0.5315 - val_acc: 0.7681\n",
      "Epoch 268/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3838 - acc: 0.8775 - val_loss: 0.5307 - val_acc: 0.7706\n",
      "Epoch 269/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3789 - acc: 0.8816 - val_loss: 0.5316 - val_acc: 0.7673\n",
      "Epoch 270/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3856 - acc: 0.8709 - val_loss: 0.5318 - val_acc: 0.7648\n",
      "Epoch 271/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3817 - acc: 0.8709 - val_loss: 0.5301 - val_acc: 0.7722\n",
      "Epoch 272/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3802 - acc: 0.8750 - val_loss: 0.5302 - val_acc: 0.7689\n",
      "Epoch 273/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3815 - acc: 0.8668 - val_loss: 0.5297 - val_acc: 0.7722\n",
      "Epoch 274/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3880 - acc: 0.8734 - val_loss: 0.5297 - val_acc: 0.7697\n",
      "Epoch 275/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3678 - acc: 0.8865 - val_loss: 0.5297 - val_acc: 0.7681\n",
      "Epoch 276/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3712 - acc: 0.8816 - val_loss: 0.5295 - val_acc: 0.7681\n",
      "Epoch 277/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.3695 - acc: 0.8898 - val_loss: 0.5284 - val_acc: 0.7730\n",
      "Epoch 278/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3716 - acc: 0.8783 - val_loss: 0.5288 - val_acc: 0.7689\n",
      "Epoch 279/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3747 - acc: 0.8775 - val_loss: 0.5283 - val_acc: 0.7706\n",
      "Epoch 280/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3782 - acc: 0.8783 - val_loss: 0.5280 - val_acc: 0.7697\n",
      "Epoch 281/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.3667 - acc: 0.8857 - val_loss: 0.5278 - val_acc: 0.7697\n",
      "Epoch 282/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.3680 - acc: 0.8824 - val_loss: 0.5280 - val_acc: 0.7689\n",
      "Epoch 283/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.3701 - acc: 0.8717 - val_loss: 0.5266 - val_acc: 0.7738\n",
      "Epoch 284/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3660 - acc: 0.8857 - val_loss: 0.5275 - val_acc: 0.7689\n",
      "Epoch 285/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3608 - acc: 0.8873 - val_loss: 0.5274 - val_acc: 0.7689\n",
      "Epoch 286/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3536 - acc: 0.8882 - val_loss: 0.5280 - val_acc: 0.7673\n",
      "Epoch 287/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3618 - acc: 0.8791 - val_loss: 0.5273 - val_acc: 0.7681\n",
      "Epoch 288/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3565 - acc: 0.8906 - val_loss: 0.5266 - val_acc: 0.7706\n",
      "Epoch 289/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3679 - acc: 0.8643 - val_loss: 0.5249 - val_acc: 0.7738\n",
      "Epoch 290/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3535 - acc: 0.8865 - val_loss: 0.5267 - val_acc: 0.7689\n",
      "Epoch 291/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3537 - acc: 0.8775 - val_loss: 0.5255 - val_acc: 0.7714\n",
      "Epoch 292/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3534 - acc: 0.8882 - val_loss: 0.5247 - val_acc: 0.7738\n",
      "Epoch 293/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3565 - acc: 0.8824 - val_loss: 0.5251 - val_acc: 0.7722\n",
      "Epoch 294/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3707 - acc: 0.8734 - val_loss: 0.5249 - val_acc: 0.7747\n",
      "Epoch 295/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.3470 - acc: 0.8873 - val_loss: 0.5243 - val_acc: 0.7730\n",
      "Epoch 296/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3526 - acc: 0.8808 - val_loss: 0.5234 - val_acc: 0.7747\n",
      "Epoch 297/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3450 - acc: 0.8849 - val_loss: 0.5234 - val_acc: 0.7771\n",
      "Epoch 298/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3576 - acc: 0.8849 - val_loss: 0.5245 - val_acc: 0.7722\n",
      "Epoch 299/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3501 - acc: 0.8914 - val_loss: 0.5243 - val_acc: 0.7722\n",
      "Epoch 300/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3530 - acc: 0.8890 - val_loss: 0.5238 - val_acc: 0.7730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3486 - acc: 0.8890 - val_loss: 0.5240 - val_acc: 0.7714\n",
      "Epoch 302/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3441 - acc: 0.8849 - val_loss: 0.5249 - val_acc: 0.7689\n",
      "Epoch 303/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3439 - acc: 0.8931 - val_loss: 0.5238 - val_acc: 0.7714\n",
      "Epoch 304/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3397 - acc: 0.8972 - val_loss: 0.5232 - val_acc: 0.7730\n",
      "Epoch 305/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3449 - acc: 0.8914 - val_loss: 0.5235 - val_acc: 0.7730\n",
      "Epoch 306/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3416 - acc: 0.8898 - val_loss: 0.5231 - val_acc: 0.7730\n",
      "Epoch 307/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3331 - acc: 0.8931 - val_loss: 0.5252 - val_acc: 0.7664\n",
      "Epoch 308/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3421 - acc: 0.8865 - val_loss: 0.5238 - val_acc: 0.7730\n",
      "Epoch 309/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3330 - acc: 0.8906 - val_loss: 0.5226 - val_acc: 0.7738\n",
      "Epoch 310/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3419 - acc: 0.8791 - val_loss: 0.5234 - val_acc: 0.7730\n",
      "Epoch 311/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3317 - acc: 0.8988 - val_loss: 0.5236 - val_acc: 0.7730\n",
      "Epoch 312/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3319 - acc: 0.8840 - val_loss: 0.5230 - val_acc: 0.7730\n",
      "Epoch 313/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3385 - acc: 0.9038 - val_loss: 0.5211 - val_acc: 0.7755\n",
      "Epoch 314/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3385 - acc: 0.8832 - val_loss: 0.5220 - val_acc: 0.7738\n",
      "Epoch 315/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3417 - acc: 0.8898 - val_loss: 0.5221 - val_acc: 0.7747\n",
      "Epoch 316/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3367 - acc: 0.8849 - val_loss: 0.5233 - val_acc: 0.7730\n",
      "Epoch 317/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3296 - acc: 0.8939 - val_loss: 0.5222 - val_acc: 0.7738\n",
      "Epoch 318/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3358 - acc: 0.8914 - val_loss: 0.5225 - val_acc: 0.7722\n",
      "Epoch 319/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3277 - acc: 0.8972 - val_loss: 0.5223 - val_acc: 0.7730\n",
      "Epoch 320/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3275 - acc: 0.8956 - val_loss: 0.5226 - val_acc: 0.7738\n",
      "Epoch 321/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3262 - acc: 0.8972 - val_loss: 0.5231 - val_acc: 0.7747\n",
      "Epoch 322/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3248 - acc: 0.8972 - val_loss: 0.5219 - val_acc: 0.7738\n",
      "Epoch 323/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3156 - acc: 0.9046 - val_loss: 0.5230 - val_acc: 0.7755\n",
      "Epoch 324/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3157 - acc: 0.9013 - val_loss: 0.5215 - val_acc: 0.7722\n",
      "Epoch 325/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3086 - acc: 0.9161 - val_loss: 0.5220 - val_acc: 0.7738\n",
      "Epoch 326/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3119 - acc: 0.9153 - val_loss: 0.5230 - val_acc: 0.7738\n",
      "Epoch 327/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3186 - acc: 0.8972 - val_loss: 0.5221 - val_acc: 0.7738\n",
      "Epoch 328/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3288 - acc: 0.8923 - val_loss: 0.5212 - val_acc: 0.7730\n",
      "Epoch 329/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3147 - acc: 0.9021 - val_loss: 0.5218 - val_acc: 0.7738\n",
      "Epoch 330/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3142 - acc: 0.8972 - val_loss: 0.5217 - val_acc: 0.7730\n",
      "Epoch 331/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3192 - acc: 0.8931 - val_loss: 0.5208 - val_acc: 0.7771\n",
      "Epoch 332/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3244 - acc: 0.8865 - val_loss: 0.5229 - val_acc: 0.7747\n",
      "Epoch 333/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3059 - acc: 0.9079 - val_loss: 0.5230 - val_acc: 0.7730\n",
      "Epoch 334/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3168 - acc: 0.8980 - val_loss: 0.5210 - val_acc: 0.7738\n",
      "Epoch 335/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3076 - acc: 0.8972 - val_loss: 0.5220 - val_acc: 0.7714\n",
      "Epoch 336/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3121 - acc: 0.8988 - val_loss: 0.5221 - val_acc: 0.7714\n",
      "Epoch 337/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3032 - acc: 0.9137 - val_loss: 0.5221 - val_acc: 0.7714\n",
      "Epoch 338/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3099 - acc: 0.8980 - val_loss: 0.5218 - val_acc: 0.7722\n",
      "Epoch 339/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3091 - acc: 0.9038 - val_loss: 0.5209 - val_acc: 0.7738\n",
      "Epoch 340/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3137 - acc: 0.8947 - val_loss: 0.5220 - val_acc: 0.7706\n",
      "Epoch 341/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3053 - acc: 0.9153 - val_loss: 0.5210 - val_acc: 0.7738\n",
      "Epoch 342/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3110 - acc: 0.8980 - val_loss: 0.5213 - val_acc: 0.7730\n",
      "Epoch 343/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2924 - acc: 0.9145 - val_loss: 0.5219 - val_acc: 0.7706\n",
      "Epoch 344/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.3031 - acc: 0.8972 - val_loss: 0.5212 - val_acc: 0.7730\n",
      "Epoch 345/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3030 - acc: 0.9095 - val_loss: 0.5213 - val_acc: 0.7730\n",
      "Epoch 346/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2912 - acc: 0.9153 - val_loss: 0.5226 - val_acc: 0.7722\n",
      "Epoch 347/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3090 - acc: 0.8988 - val_loss: 0.5225 - val_acc: 0.7706\n",
      "Epoch 348/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2998 - acc: 0.9112 - val_loss: 0.5213 - val_acc: 0.7738\n",
      "Epoch 349/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3039 - acc: 0.9005 - val_loss: 0.5212 - val_acc: 0.7747\n",
      "Epoch 350/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.3009 - acc: 0.9038 - val_loss: 0.5217 - val_acc: 0.7730\n",
      "Epoch 351/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2933 - acc: 0.9104 - val_loss: 0.5204 - val_acc: 0.7788\n",
      "Epoch 352/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2951 - acc: 0.9038 - val_loss: 0.5222 - val_acc: 0.7697\n",
      "Epoch 353/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2943 - acc: 0.9054 - val_loss: 0.5212 - val_acc: 0.7763\n",
      "Epoch 354/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2831 - acc: 0.9169 - val_loss: 0.5216 - val_acc: 0.7738\n",
      "Epoch 355/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2995 - acc: 0.8980 - val_loss: 0.5213 - val_acc: 0.7788\n",
      "Epoch 356/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2878 - acc: 0.9243 - val_loss: 0.5216 - val_acc: 0.7755\n",
      "Epoch 357/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2959 - acc: 0.9021 - val_loss: 0.5213 - val_acc: 0.7788\n",
      "Epoch 358/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2851 - acc: 0.9120 - val_loss: 0.5228 - val_acc: 0.7706\n",
      "Epoch 359/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2909 - acc: 0.9062 - val_loss: 0.5231 - val_acc: 0.7673\n",
      "Epoch 360/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2907 - acc: 0.9071 - val_loss: 0.5219 - val_acc: 0.7755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2846 - acc: 0.9120 - val_loss: 0.5214 - val_acc: 0.7796\n",
      "Epoch 362/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2987 - acc: 0.9046 - val_loss: 0.5205 - val_acc: 0.7812\n",
      "Epoch 363/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2864 - acc: 0.9046 - val_loss: 0.5232 - val_acc: 0.7714\n",
      "Epoch 364/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2779 - acc: 0.9219 - val_loss: 0.5232 - val_acc: 0.7714\n",
      "Epoch 365/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2752 - acc: 0.9309 - val_loss: 0.5232 - val_acc: 0.7714\n",
      "Epoch 366/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2909 - acc: 0.9021 - val_loss: 0.5217 - val_acc: 0.7804\n",
      "Epoch 367/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2905 - acc: 0.9153 - val_loss: 0.5233 - val_acc: 0.7714\n",
      "Epoch 368/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2895 - acc: 0.9145 - val_loss: 0.5237 - val_acc: 0.7706\n",
      "Epoch 369/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2703 - acc: 0.9128 - val_loss: 0.5237 - val_acc: 0.7706\n",
      "Epoch 370/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2816 - acc: 0.9178 - val_loss: 0.5227 - val_acc: 0.7755\n",
      "Epoch 371/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2734 - acc: 0.9178 - val_loss: 0.5236 - val_acc: 0.7722\n",
      "Epoch 372/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2749 - acc: 0.9194 - val_loss: 0.5246 - val_acc: 0.7706\n",
      "Epoch 373/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2865 - acc: 0.8931 - val_loss: 0.5248 - val_acc: 0.7706\n",
      "Epoch 374/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2767 - acc: 0.9202 - val_loss: 0.5237 - val_acc: 0.7747\n",
      "Epoch 375/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2744 - acc: 0.9186 - val_loss: 0.5232 - val_acc: 0.7755\n",
      "Epoch 376/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2649 - acc: 0.9243 - val_loss: 0.5237 - val_acc: 0.7755\n",
      "Epoch 377/400\n",
      "1216/1216 [==============================] - 2s 1ms/step - loss: 0.2614 - acc: 0.9268 - val_loss: 0.5247 - val_acc: 0.7714\n",
      "Epoch 378/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2754 - acc: 0.9128 - val_loss: 0.5241 - val_acc: 0.7738\n",
      "Epoch 379/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2713 - acc: 0.9137 - val_loss: 0.5251 - val_acc: 0.7714\n",
      "Epoch 380/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2770 - acc: 0.9087 - val_loss: 0.5240 - val_acc: 0.7763\n",
      "Epoch 381/400\n",
      "1216/1216 [==============================] - 3s 2ms/step - loss: 0.2720 - acc: 0.9112 - val_loss: 0.5243 - val_acc: 0.7747\n",
      "Epoch 382/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2678 - acc: 0.9178 - val_loss: 0.5251 - val_acc: 0.7714\n",
      "Epoch 383/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2671 - acc: 0.9243 - val_loss: 0.5233 - val_acc: 0.7804\n",
      "Epoch 384/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2706 - acc: 0.9153 - val_loss: 0.5240 - val_acc: 0.7821\n",
      "Epoch 385/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2737 - acc: 0.9169 - val_loss: 0.5254 - val_acc: 0.7714\n",
      "Epoch 386/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2665 - acc: 0.9186 - val_loss: 0.5244 - val_acc: 0.7812\n",
      "Epoch 387/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2739 - acc: 0.9153 - val_loss: 0.5238 - val_acc: 0.7812\n",
      "Epoch 388/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2650 - acc: 0.9194 - val_loss: 0.5241 - val_acc: 0.7812\n",
      "Epoch 389/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2663 - acc: 0.9219 - val_loss: 0.5243 - val_acc: 0.7821\n",
      "Epoch 390/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2663 - acc: 0.9227 - val_loss: 0.5253 - val_acc: 0.7771\n",
      "Epoch 391/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2685 - acc: 0.9128 - val_loss: 0.5258 - val_acc: 0.7755\n",
      "Epoch 392/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2652 - acc: 0.9235 - val_loss: 0.5255 - val_acc: 0.7771\n",
      "Epoch 393/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2626 - acc: 0.9161 - val_loss: 0.5250 - val_acc: 0.7812\n",
      "Epoch 394/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2544 - acc: 0.9268 - val_loss: 0.5281 - val_acc: 0.7697\n",
      "Epoch 395/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2522 - acc: 0.9359 - val_loss: 0.5266 - val_acc: 0.7755\n",
      "Epoch 396/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2584 - acc: 0.9202 - val_loss: 0.5257 - val_acc: 0.7804\n",
      "Epoch 397/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2613 - acc: 0.9120 - val_loss: 0.5264 - val_acc: 0.7780\n",
      "Epoch 398/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2559 - acc: 0.9219 - val_loss: 0.5260 - val_acc: 0.7829\n",
      "Epoch 399/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2464 - acc: 0.9326 - val_loss: 0.5270 - val_acc: 0.7771\n",
      "Epoch 400/400\n",
      "1216/1216 [==============================] - 2s 2ms/step - loss: 0.2554 - acc: 0.9153 - val_loss: 0.5270 - val_acc: 0.7788\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, epochs=nb_epoch, batch_size=batch_size, \n",
    "          validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c9883e75c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 200 into shape (135,135,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-ede0fc96d4f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mwt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m135\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m135\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CSIRO\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    230\u001b[0m            [5, 6]])\n\u001b[0;32m    231\u001b[0m     \"\"\"\n\u001b[1;32m--> 232\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\CSIRO\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 200 into shape (135,135,2)"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "\n",
    "wt = np.reshape(weights[0], (135, 135, 2))\n",
    "    \n",
    "for n in range(0, wt.shape[2]):\n",
    "   plt.imshow(wt[:,:,n], cmap='gray', shape=(135, 135))\n",
    "   print (n)\n",
    "   plt.show()\n",
    "\n",
    "print (\"Dense to output layer weights \" + str(weights[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
